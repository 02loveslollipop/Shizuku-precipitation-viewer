{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62bcf1b",
   "metadata": {},
   "source": [
    "# Extreme Weather Data Analysis\n",
    "\n",
    "This notebook analyzes historical precipitation data from 2020-2024 to find the timestamps with the highest mean precipitation values. We'll then generate grids and contours for these extreme weather events to test how the map visualization handles more \"wild\" data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5358063b",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "First, let's import the required libraries and set up database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from datetime import datetime, timezone\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the services directory to the path so we can import ETL modules\n",
    "services_path = Path('../services').resolve()\n",
    "sys.path.append(str(services_path))\n",
    "\n",
    "print(f\"Services path: {services_path}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c39c49",
   "metadata": {},
   "source": [
    "## Database Connection Setup\n",
    "\n",
    "Set up the database connection. You'll need to provide your DATABASE_URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5698dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database configuration\n",
    "# Replace with your actual database URL\n",
    "DATABASE_URL = os.getenv('DATABASE_URL', 'postgresql://username:password@host:port/database')\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"Create a database connection\"\"\"\n",
    "    return psycopg2.connect(DATABASE_URL)\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    with get_db_connection() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT 1\")\n",
    "            print(\"✅ Database connection successful\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Database connection failed: {e}\")\n",
    "    print(\"Please set the DATABASE_URL environment variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed006e8",
   "metadata": {},
   "source": [
    "## Analyze Historical Data (2020-2024)\n",
    "\n",
    "Let's find the timestamps with the highest mean precipitation values from the historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_extreme_weather_timestamps(limit=10):\n",
    "    \"\"\"Find timestamps with highest mean precipitation values from 2020-2024\"\"\"\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        DATE_TRUNC('hour', ts) as hour_slot,\n",
    "        COUNT(*) as sensor_count,\n",
    "        AVG(value_mm) as mean_precipitation,\n",
    "        MAX(value_mm) as max_precipitation,\n",
    "        STDDEV(value_mm) as std_precipitation,\n",
    "        SUM(value_mm) as total_precipitation\n",
    "    FROM clean_measurements \n",
    "    WHERE ts >= '2020-01-01' \n",
    "      AND ts < '2025-01-01'\n",
    "      AND value_mm > 0  -- Only consider timestamps with actual precipitation\n",
    "    GROUP BY hour_slot\n",
    "    HAVING COUNT(*) >= 5  -- At least 5 sensors reporting\n",
    "       AND AVG(value_mm) > 1.0  -- Significant precipitation events\n",
    "    ORDER BY mean_precipitation DESC\n",
    "    LIMIT %s;\n",
    "    \"\"\"\n",
    "    \n",
    "    with get_db_connection() as conn:\n",
    "        df = pd.read_sql_query(query, conn, params=[limit])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Find the top 10 extreme weather events\n",
    "extreme_events = find_extreme_weather_timestamps(10)\n",
    "print(f\"Found {len(extreme_events)} extreme weather events:\")\n",
    "print(extreme_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0747f4",
   "metadata": {},
   "source": [
    "## Visualize the Extreme Events\n",
    "\n",
    "Let's visualize these extreme precipitation events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7665843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Mean precipitation over time\n",
    "axes[0, 0].bar(range(len(extreme_events)), extreme_events['mean_precipitation'])\n",
    "axes[0, 0].set_title('Mean Precipitation by Event Rank')\n",
    "axes[0, 0].set_xlabel('Event Rank (1 = highest)')\n",
    "axes[0, 0].set_ylabel('Mean Precipitation (mm)')\n",
    "axes[0, 0].set_xticks(range(len(extreme_events)))\n",
    "axes[0, 0].set_xticklabels([f\"{i+1}\" for i in range(len(extreme_events))])\n",
    "\n",
    "# 2. Max vs Mean precipitation\n",
    "axes[0, 1].scatter(extreme_events['mean_precipitation'], extreme_events['max_precipitation'], \n",
    "                   s=extreme_events['sensor_count']*10, alpha=0.6)\n",
    "axes[0, 1].set_title('Max vs Mean Precipitation\\n(bubble size = sensor count)')\n",
    "axes[0, 1].set_xlabel('Mean Precipitation (mm)')\n",
    "axes[0, 1].set_ylabel('Max Precipitation (mm)')\n",
    "\n",
    "# 3. Sensor count distribution\n",
    "axes[1, 0].bar(range(len(extreme_events)), extreme_events['sensor_count'])\n",
    "axes[1, 0].set_title('Number of Sensors Reporting')\n",
    "axes[1, 0].set_xlabel('Event Rank')\n",
    "axes[1, 0].set_ylabel('Sensor Count')\n",
    "axes[1, 0].set_xticks(range(len(extreme_events)))\n",
    "axes[1, 0].set_xticklabels([f\"{i+1}\" for i in range(len(extreme_events))])\n",
    "\n",
    "# 4. Timeline of events\n",
    "extreme_events['hour_slot'] = pd.to_datetime(extreme_events['hour_slot'])\n",
    "axes[1, 1].scatter(extreme_events['hour_slot'], extreme_events['mean_precipitation'], \n",
    "                   s=100, alpha=0.7)\n",
    "axes[1, 1].set_title('Timeline of Extreme Events')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Mean Precipitation (mm)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display detailed information about the top 5 events\n",
    "print(\"\\n🌧️ TOP 5 EXTREME WEATHER EVENTS:\")\n",
    "print(\"=\" * 80)\n",
    "for i, row in extreme_events.head(5).iterrows():\n",
    "    print(f\"Rank {i+1}: {row['hour_slot']}\")\n",
    "    print(f\"  Mean: {row['mean_precipitation']:.2f}mm | Max: {row['max_precipitation']:.2f}mm\")\n",
    "    print(f\"  Sensors: {row['sensor_count']} | Total: {row['total_precipitation']:.2f}mm\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d091e84",
   "metadata": {},
   "source": [
    "## Check Existing Grid Runs\n",
    "\n",
    "Let's check if grids already exist for these timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_existing_grids(timestamps):\n",
    "    \"\"\"Check which timestamps already have grid runs\"\"\"\n",
    "    \n",
    "    # Convert timestamps to string format for SQL query\n",
    "    timestamp_list = [ts.strftime('%Y-%m-%d %H:00:00+00') for ts in timestamps]\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT ts, status, blob_url_json, blob_url_contours, message\n",
    "    FROM grid_runs \n",
    "    WHERE ts = ANY(%s)\n",
    "    ORDER BY ts DESC;\n",
    "    \"\"\"\n",
    "    \n",
    "    with get_db_connection() as conn:\n",
    "        df = pd.read_sql_query(query, conn, params=[timestamp_list])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Check existing grids\n",
    "existing_grids = check_existing_grids(extreme_events['hour_slot'])\n",
    "print(f\"Existing grid runs for extreme events: {len(existing_grids)}\")\n",
    "if len(existing_grids) > 0:\n",
    "    print(existing_grids[['ts', 'status', 'message']].head())\n",
    "else:\n",
    "    print(\"No existing grids found for these timestamps.\")\n",
    "\n",
    "# Identify timestamps that need grid generation\n",
    "if len(existing_grids) > 0:\n",
    "    existing_timestamps = set(existing_grids['ts'])\n",
    "    needed_timestamps = [ts for ts in extreme_events['hour_slot'] \n",
    "                        if ts not in existing_timestamps]\n",
    "else:\n",
    "    needed_timestamps = list(extreme_events['hour_slot'])\n",
    "\n",
    "print(f\"\\nTimestamps needing grid generation: {len(needed_timestamps)}\")\n",
    "for ts in needed_timestamps[:5]:  # Show first 5\n",
    "    print(f\"  - {ts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2b3ce",
   "metadata": {},
   "source": [
    "## Generate Grid Runs for Extreme Events\n",
    "\n",
    "Now let's create grid run entries for the extreme weather timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e699fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_run_entries(timestamps, resolution_m=500):\n",
    "    \"\"\"Create grid run entries for the specified timestamps\"\"\"\n",
    "    \n",
    "    # Default bounding box for Antioquia region\n",
    "    bbox = {\n",
    "        \"west\": -77.2,\n",
    "        \"south\": 4.8, \n",
    "        \"east\": -73.5,\n",
    "        \"north\": 8.8\n",
    "    }\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO grid_runs (ts, res_m, bbox, status, message)\n",
    "    VALUES (%s, %s, %s, 'pending', 'Created for extreme weather analysis')\n",
    "    ON CONFLICT (ts, res_m) DO NOTHING\n",
    "    RETURNING id, ts;\n",
    "    \"\"\"\n",
    "    \n",
    "    created_count = 0\n",
    "    \n",
    "    with get_db_connection() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            for ts in timestamps:\n",
    "                try:\n",
    "                    cur.execute(insert_query, (\n",
    "                        ts.strftime('%Y-%m-%d %H:00:00+00'),\n",
    "                        resolution_m,\n",
    "                        json.dumps(bbox)\n",
    "                    ))\n",
    "                    result = cur.fetchone()\n",
    "                    if result:\n",
    "                        created_count += 1\n",
    "                        print(f\"✅ Created grid run {result[0]} for {result[1]}\")\n",
    "                    else:\n",
    "                        print(f\"⚠️  Grid run already exists for {ts}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error creating grid run for {ts}: {e}\")\n",
    "            \n",
    "            conn.commit()\n",
    "    \n",
    "    return created_count\n",
    "\n",
    "# Import json for bbox serialization\n",
    "import json\n",
    "\n",
    "# Create grid run entries for timestamps that need them\n",
    "if needed_timestamps:\n",
    "    print(f\"Creating grid run entries for {len(needed_timestamps)} timestamps...\")\n",
    "    created = create_grid_run_entries(needed_timestamps[:10])  # Limit to top 10\n",
    "    print(f\"\\n✅ Created {created} new grid run entries\")\n",
    "else:\n",
    "    print(\"All extreme weather timestamps already have grid runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637e41d8",
   "metadata": {},
   "source": [
    "## Run the ETL Service\n",
    "\n",
    "Now let's run the ETL service to generate the actual grids and contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ETL modules\n",
    "try:\n",
    "    from etl.main import run as run_etl\n",
    "    from etl.config import load as load_config\n",
    "    print(\"✅ ETL modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Failed to import ETL modules: {e}\")\n",
    "    print(\"Make sure you have the required environment variables set:\")\n",
    "    print(\"- DATABASE_URL\")\n",
    "    print(\"- VERCEL_BLOB_RW_TOKEN\")\n",
    "    print(\"- VERCEL_BLOB_BASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc39ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables for ETL (you need to provide these)\n",
    "os.environ['GRID_INTERVAL_MIN'] = '60'\n",
    "os.environ['GRID_RESOLUTION_M'] = '500'\n",
    "os.environ['ETL_MAX_SLOTS'] = '10'  # Process up to 10 slots\n",
    "os.environ['DRY_RUN'] = 'false'  # Set to 'true' for testing without uploads\n",
    "\n",
    "# Check required environment variables\n",
    "required_vars = ['DATABASE_URL', 'VERCEL_BLOB_RW_TOKEN', 'VERCEL_BLOB_BASE_URL']\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"❌ Missing required environment variables: {missing_vars}\")\n",
    "    print(\"Please set these before running the ETL:\")\n",
    "    for var in missing_vars:\n",
    "        print(f\"export {var}=your_value_here\")\n",
    "else:\n",
    "    print(\"✅ All required environment variables are set\")\n",
    "    print(\"Ready to run ETL service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ETL service (uncomment when ready)\n",
    "# WARNING: This will process pending grid runs and upload to Vercel Blob storage\n",
    "\n",
    "if not missing_vars:\n",
    "    print(\"🚀 Starting ETL service for extreme weather data...\")\n",
    "    print(\"This may take several minutes depending on the amount of data.\")\n",
    "    \n",
    "    try:\n",
    "        run_etl()\n",
    "        print(\"✅ ETL service completed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ETL service failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"⚠️  Skipping ETL run due to missing environment variables\")\n",
    "    print(\"Set DRY_RUN=true if you want to test without uploads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c3ceeb",
   "metadata": {},
   "source": [
    "## Check Results\n",
    "\n",
    "Let's check the results of the grid generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db367f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grid_results():\n",
    "    \"\"\"Check the status of grid runs for extreme weather events\"\"\"\n",
    "    \n",
    "    # Get the extreme event timestamps again\n",
    "    timestamp_list = [ts.strftime('%Y-%m-%d %H:00:00+00') for ts in extreme_events['hour_slot']]\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        ts,\n",
    "        status,\n",
    "        CASE \n",
    "            WHEN blob_url_json IS NOT NULL THEN 'Yes'\n",
    "            ELSE 'No'\n",
    "        END as has_grid_data,\n",
    "        CASE \n",
    "            WHEN blob_url_contours IS NOT NULL THEN 'Yes'\n",
    "            ELSE 'No'\n",
    "        END as has_contours,\n",
    "        message,\n",
    "        updated_at\n",
    "    FROM grid_runs \n",
    "    WHERE ts = ANY(%s)\n",
    "    ORDER BY ts DESC;\n",
    "    \"\"\"\n",
    "    \n",
    "    with get_db_connection() as conn:\n",
    "        df = pd.read_sql_query(query, conn, params=[timestamp_list])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Check results\n",
    "results = check_grid_results()\n",
    "print(f\"Grid run results for {len(results)} extreme weather events:\")\n",
    "print(\"=\" * 80)\n",
    "print(results[['ts', 'status', 'has_grid_data', 'has_contours', 'message']].to_string())\n",
    "\n",
    "# Summary statistics\n",
    "status_counts = results['status'].value_counts()\n",
    "print(f\"\\n📊 SUMMARY:\")\n",
    "print(f\"✅ Done: {status_counts.get('done', 0)}\")\n",
    "print(f\"⏳ Pending: {status_counts.get('pending', 0)}\")\n",
    "print(f\"❌ Failed: {status_counts.get('failed', 0)}\")\n",
    "\n",
    "successful_grids = results[results['status'] == 'done']\n",
    "if len(successful_grids) > 0:\n",
    "    print(f\"\\n🎉 Successfully generated {len(successful_grids)} grids for extreme weather events!\")\n",
    "    print(\"\\nThese timestamps are now available in your Flutter app for testing:\")\n",
    "    for _, row in successful_grids.iterrows():\n",
    "        print(f\"  - {row['ts']} ({row['has_grid_data']} grid, {row['has_contours']} contours)\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No grids were successfully generated yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e849612e",
   "metadata": {},
   "source": [
    "## Test the Map Visualization\n",
    "\n",
    "Instructions for testing the extreme weather data in your Flutter app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c7987",
   "metadata": {},
   "source": [
    "### 🚀 Testing Instructions\n",
    "\n",
    "Now that we've generated grids for extreme weather events, you can test them in your Flutter app:\n",
    "\n",
    "1. **Start your Flutter app** and open the precipitation viewer\n",
    "2. **Use the timeline slider** to navigate to the extreme weather timestamps we generated\n",
    "3. **Observe how the map handles** the higher precipitation values:\n",
    "   - Check if the color scale properly represents the extreme values\n",
    "   - Verify that contours display correctly for high precipitation areas\n",
    "   - Test the performance with more complex contour data\n",
    "\n",
    "### 🔍 What to Look For:\n",
    "\n",
    "- **Color saturation**: Do the highest values show distinct colors?\n",
    "- **Contour density**: Are there more contour lines in areas of high precipitation?\n",
    "- **Performance**: Does the app remain responsive with complex grid data?\n",
    "- **Scale accuracy**: Do the legend values match the displayed data?\n",
    "\n",
    "### 🛠️ Potential Adjustments:\n",
    "\n",
    "Based on your testing, you might need to:\n",
    "- Adjust the color scale thresholds in `app_constants.dart`\n",
    "- Modify contour generation parameters\n",
    "- Optimize rendering for complex datasets\n",
    "- Update the legend to better represent extreme values"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
