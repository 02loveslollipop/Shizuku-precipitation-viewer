{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "807a4066",
   "metadata": {},
   "source": [
    "# Data Backup - Current Non-Historic Data\n",
    "\n",
    "**Purpose:** Backup all current non-historic data from the database before the refactoring.\n",
    "\n",
    "**Date:** October 1, 2025\n",
    "\n",
    "This notebook will:\n",
    "1. Connect to the database\n",
    "2. Fetch all current data (sensors, clean_measurements, grid_runs)\n",
    "3. Store as JSON files for recovery\n",
    "4. Create a manifest file with metadata\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed3251",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ca6649a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c67e4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Database URL loaded\n",
      "  Database: db.shizuku.02labs.me/d6ijt5s230gvd1?sslmode=require\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(Path(\".env\"), override=False)\n",
    "\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
    "if not DATABASE_URL:\n",
    "    raise ValueError(\"DATABASE_URL not found in environment variables\")\n",
    "\n",
    "print(\"✓ Database URL loaded\")\n",
    "print(f\"  Database: {DATABASE_URL.split('@')[1] if '@' in DATABASE_URL else 'configured'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38827594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Backup directory created: data_backup/backup_20251001_121447\n"
     ]
    }
   ],
   "source": [
    "# Create backup directory\n",
    "BACKUP_DIR = Path(\"data_backup\")\n",
    "BACKUP_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Create timestamped subdirectory\n",
    "timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
    "BACKUP_SUBDIR = BACKUP_DIR / f\"backup_{timestamp}\"\n",
    "BACKUP_SUBDIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"✓ Backup directory created: {BACKUP_SUBDIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5b641fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Database connection successful\n",
      "  PostgreSQL version: PostgreSQL 17.4 on aarch64-unknown-linux-gnu\n"
     ]
    }
   ],
   "source": [
    "# Create database engine\n",
    "engine = sa.create_engine(DATABASE_URL, pool_pre_ping=True)\n",
    "\n",
    "# Test connection\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(sa.text(\"SELECT version();\"))\n",
    "    version = result.scalar()\n",
    "    print(\"✓ Database connection successful\")\n",
    "    print(f\"  PostgreSQL version: {version.split(',')[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2336ed",
   "metadata": {},
   "source": [
    "## 2. Fetch Sensors Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ec4c941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fetched 239 sensors\n",
      "  First sensor: pluvio_1\n",
      "  Last sensor: vaisala_83\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "provider_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "elevation_m",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "city",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subbasin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "barrio",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metadata",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "created_at",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "updated_at",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        }
       ],
       "ref": "f91b98d5-717b-4ed5-a969-aecda94ddc99",
       "rows": [
        [
         "0",
         "pluvio_1",
         "Casa de Gobierno Altavista",
         "1",
         "6.2226",
         "-75.6282",
         null,
         "Medellin",
         "Q. Altavista",
         "Altavista - Sector central",
         "{'barrio': 'Altavista - Sector central', 'comuna': '', 'source': 'current', 'network': 'pluvio', 'subcuenca': 'Q. Altavista'}",
         "2025-09-29 02:56:01.458825+00:00",
         "2025-10-01 12:10:50.464704+00:00"
        ],
        [
         "1",
         "pluvio_10",
         "Escuela Rural El Boqueron",
         "10",
         "6.3153338",
         "-75.657627",
         null,
         "Medellin",
         "Q. La Iguana",
         "Boqueron",
         "{'barrio': 'Boqueron', 'comuna': '', 'source': 'current', 'network': 'pluvio', 'subcuenca': 'Q. La Iguana'}",
         "2025-09-29 02:56:01.458825+00:00",
         "2025-10-01 12:10:50.464704+00:00"
        ],
        [
         "2",
         "pluvio_1019",
         "Torre SIATA - Thies",
         "1019",
         "6.259215",
         "-75.58864",
         null,
         "Medellin",
         "Q. La Hueso",
         "",
         "{'barrio': '', 'comuna': '', 'source': 'current', 'network': 'pluvio', 'subcuenca': 'Q. La Hueso'}",
         "2025-09-29 02:56:01.458825+00:00",
         "2025-10-01 12:10:50.464704+00:00"
        ],
        [
         "3",
         "pluvio_105",
         "Parque 3 Aguas",
         "105",
         "6.09628",
         "-75.63536",
         null,
         "Caldas",
         "R. Aburra-Medellin",
         "La Miel",
         "{'barrio': 'La Miel', 'comuna': '', 'source': 'current', 'network': 'pluvio', 'subcuenca': 'R. Aburra-Medellin'}",
         "2025-09-29 02:56:01.458825+00:00",
         "2025-10-01 12:10:50.464704+00:00"
        ],
        [
         "4",
         "pluvio_11",
         "Escuela Rural Fabio Zuluaga",
         "11",
         "6.273131",
         "-75.651637",
         null,
         "Medellin",
         "Q. La Iguana",
         "La Palma",
         "{'barrio': 'La Palma', 'comuna': '', 'source': 'current', 'network': 'pluvio', 'subcuenca': 'Q. La Iguana'}",
         "2025-09-29 02:56:01.458825+00:00",
         "2025-10-01 12:10:50.464704+00:00"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>elevation_m</th>\n",
       "      <th>city</th>\n",
       "      <th>subbasin</th>\n",
       "      <th>barrio</th>\n",
       "      <th>metadata</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pluvio_1</td>\n",
       "      <td>Casa de Gobierno Altavista</td>\n",
       "      <td>1</td>\n",
       "      <td>6.222600</td>\n",
       "      <td>-75.628200</td>\n",
       "      <td>None</td>\n",
       "      <td>Medellin</td>\n",
       "      <td>Q. Altavista</td>\n",
       "      <td>Altavista - Sector central</td>\n",
       "      <td>{'barrio': 'Altavista - Sector central', 'comu...</td>\n",
       "      <td>2025-09-29 02:56:01.458825+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.464704+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pluvio_10</td>\n",
       "      <td>Escuela Rural El Boqueron</td>\n",
       "      <td>10</td>\n",
       "      <td>6.315334</td>\n",
       "      <td>-75.657627</td>\n",
       "      <td>None</td>\n",
       "      <td>Medellin</td>\n",
       "      <td>Q. La Iguana</td>\n",
       "      <td>Boqueron</td>\n",
       "      <td>{'barrio': 'Boqueron', 'comuna': '', 'source':...</td>\n",
       "      <td>2025-09-29 02:56:01.458825+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.464704+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pluvio_1019</td>\n",
       "      <td>Torre SIATA - Thies</td>\n",
       "      <td>1019</td>\n",
       "      <td>6.259215</td>\n",
       "      <td>-75.588640</td>\n",
       "      <td>None</td>\n",
       "      <td>Medellin</td>\n",
       "      <td>Q. La Hueso</td>\n",
       "      <td></td>\n",
       "      <td>{'barrio': '', 'comuna': '', 'source': 'curren...</td>\n",
       "      <td>2025-09-29 02:56:01.458825+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.464704+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pluvio_105</td>\n",
       "      <td>Parque 3 Aguas</td>\n",
       "      <td>105</td>\n",
       "      <td>6.096280</td>\n",
       "      <td>-75.635360</td>\n",
       "      <td>None</td>\n",
       "      <td>Caldas</td>\n",
       "      <td>R. Aburra-Medellin</td>\n",
       "      <td>La Miel</td>\n",
       "      <td>{'barrio': 'La Miel', 'comuna': '', 'source': ...</td>\n",
       "      <td>2025-09-29 02:56:01.458825+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.464704+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pluvio_11</td>\n",
       "      <td>Escuela Rural Fabio Zuluaga</td>\n",
       "      <td>11</td>\n",
       "      <td>6.273131</td>\n",
       "      <td>-75.651637</td>\n",
       "      <td>None</td>\n",
       "      <td>Medellin</td>\n",
       "      <td>Q. La Iguana</td>\n",
       "      <td>La Palma</td>\n",
       "      <td>{'barrio': 'La Palma', 'comuna': '', 'source':...</td>\n",
       "      <td>2025-09-29 02:56:01.458825+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.464704+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                         name provider_id       lat        lon  \\\n",
       "0     pluvio_1   Casa de Gobierno Altavista           1  6.222600 -75.628200   \n",
       "1    pluvio_10    Escuela Rural El Boqueron          10  6.315334 -75.657627   \n",
       "2  pluvio_1019          Torre SIATA - Thies        1019  6.259215 -75.588640   \n",
       "3   pluvio_105               Parque 3 Aguas         105  6.096280 -75.635360   \n",
       "4    pluvio_11  Escuela Rural Fabio Zuluaga          11  6.273131 -75.651637   \n",
       "\n",
       "  elevation_m      city            subbasin                      barrio  \\\n",
       "0        None  Medellin        Q. Altavista  Altavista - Sector central   \n",
       "1        None  Medellin        Q. La Iguana                    Boqueron   \n",
       "2        None  Medellin         Q. La Hueso                               \n",
       "3        None    Caldas  R. Aburra-Medellin                     La Miel   \n",
       "4        None  Medellin        Q. La Iguana                    La Palma   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'barrio': 'Altavista - Sector central', 'comu...   \n",
       "1  {'barrio': 'Boqueron', 'comuna': '', 'source':...   \n",
       "2  {'barrio': '', 'comuna': '', 'source': 'curren...   \n",
       "3  {'barrio': 'La Miel', 'comuna': '', 'source': ...   \n",
       "4  {'barrio': 'La Palma', 'comuna': '', 'source':...   \n",
       "\n",
       "                        created_at                       updated_at  \n",
       "0 2025-09-29 02:56:01.458825+00:00 2025-10-01 12:10:50.464704+00:00  \n",
       "1 2025-09-29 02:56:01.458825+00:00 2025-10-01 12:10:50.464704+00:00  \n",
       "2 2025-09-29 02:56:01.458825+00:00 2025-10-01 12:10:50.464704+00:00  \n",
       "3 2025-09-29 02:56:01.458825+00:00 2025-10-01 12:10:50.464704+00:00  \n",
       "4 2025-09-29 02:56:01.458825+00:00 2025-10-01 12:10:50.464704+00:00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch all sensors\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    name,\n",
    "    provider_id,\n",
    "    lat,\n",
    "    lon,\n",
    "    elevation_m,\n",
    "    city,\n",
    "    subbasin,\n",
    "    barrio,\n",
    "    metadata,\n",
    "    created_at,\n",
    "    updated_at\n",
    "FROM sensors\n",
    "ORDER BY id;\n",
    "\"\"\"\n",
    "\n",
    "sensors_df = pd.read_sql(query, engine)\n",
    "\n",
    "print(f\"✓ Fetched {len(sensors_df)} sensors\")\n",
    "print(f\"  First sensor: {sensors_df['id'].iloc[0] if len(sensors_df) > 0 else 'N/A'}\")\n",
    "print(f\"  Last sensor: {sensors_df['id'].iloc[-1] if len(sensors_df) > 0 else 'N/A'}\")\n",
    "\n",
    "sensors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2195a4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved sensors to: data_backup/backup_20251001_121447/sensors.json\n",
      "  File size: 122.76 KB\n"
     ]
    }
   ],
   "source": [
    "# Save sensors to JSON\n",
    "sensors_file = BACKUP_SUBDIR / \"sensors.json\"\n",
    "\n",
    "# Convert timestamps to ISO format\n",
    "sensors_export = sensors_df.copy()\n",
    "sensors_export['created_at'] = sensors_export['created_at'].astype(str)\n",
    "sensors_export['updated_at'] = sensors_export['updated_at'].astype(str)\n",
    "\n",
    "# Convert to dict and save\n",
    "sensors_data = sensors_export.to_dict(orient='records')\n",
    "with open(sensors_file, 'w') as f:\n",
    "    json.dump(sensors_data, f, indent=2, default=str)\n",
    "\n",
    "print(f\"✓ Saved sensors to: {sensors_file}\")\n",
    "print(f\"  File size: {sensors_file.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e239fb5",
   "metadata": {},
   "source": [
    "## 3. Fetch Clean Measurements (Non-Historic)\n",
    "\n",
    "We'll fetch clean measurements from the last 30 days to capture current operational data.\n",
    "\n",
    "**Note:** Clean measurements may include imputed values using:\n",
    "- **Primary method:** ARIMA (AutoRegressive Integrated Moving Average)\n",
    "- **Fallback method:** 0 (zero) when ARIMA cannot be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca8d532b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fetched 74,806 clean measurements\n",
      "  Date range: 2025-09-29 00:50:51+00:00 to 2025-10-01 12:01:15+00:00\n",
      "  Unique sensors: 226\n",
      "  Total measurements per sensor (avg): 331.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sensor_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ts",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "value_mm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "qc_flags",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "imputation_method",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "version",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "created_at",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "updated_at",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        }
       ],
       "ref": "1974e81e-c3da-4ae4-8d20-4f0670d7c687",
       "rows": [
        [
         "0",
         "636194",
         "pluvio_1",
         "2025-10-01 12:01:15+00:00",
         "0.0",
         "0",
         null,
         "1",
         "2025-10-01 12:01:22.025362+00:00",
         "2025-10-01 12:01:22.025362+00:00"
        ],
        [
         "1",
         "636195",
         "pluvio_10",
         "2025-10-01 12:01:15+00:00",
         "0.0",
         "2",
         "global_median",
         "1",
         "2025-10-01 12:01:22.025362+00:00",
         "2025-10-01 12:01:22.025362+00:00"
        ],
        [
         "2",
         "636196",
         "pluvio_1019",
         "2025-10-01 12:01:15+00:00",
         "0.0",
         "0",
         null,
         "1",
         "2025-10-01 12:01:22.025362+00:00",
         "2025-10-01 12:01:22.025362+00:00"
        ],
        [
         "3",
         "636197",
         "pluvio_105",
         "2025-10-01 12:01:15+00:00",
         "0.0",
         "0",
         null,
         "1",
         "2025-10-01 12:01:22.025362+00:00",
         "2025-10-01 12:01:22.025362+00:00"
        ],
        [
         "4",
         "636198",
         "pluvio_11",
         "2025-10-01 12:01:15+00:00",
         "0.0",
         "0",
         null,
         "1",
         "2025-10-01 12:01:22.025362+00:00",
         "2025-10-01 12:01:22.025362+00:00"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>value_mm</th>\n",
       "      <th>qc_flags</th>\n",
       "      <th>imputation_method</th>\n",
       "      <th>version</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>636194</td>\n",
       "      <td>pluvio_1</td>\n",
       "      <td>2025-10-01 12:01:15+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-10-01 12:01:22.025362+00:00</td>\n",
       "      <td>2025-10-01 12:01:22.025362+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>636195</td>\n",
       "      <td>pluvio_10</td>\n",
       "      <td>2025-10-01 12:01:15+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>global_median</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-10-01 12:01:22.025362+00:00</td>\n",
       "      <td>2025-10-01 12:01:22.025362+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>636196</td>\n",
       "      <td>pluvio_1019</td>\n",
       "      <td>2025-10-01 12:01:15+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-10-01 12:01:22.025362+00:00</td>\n",
       "      <td>2025-10-01 12:01:22.025362+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>636197</td>\n",
       "      <td>pluvio_105</td>\n",
       "      <td>2025-10-01 12:01:15+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-10-01 12:01:22.025362+00:00</td>\n",
       "      <td>2025-10-01 12:01:22.025362+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636198</td>\n",
       "      <td>pluvio_11</td>\n",
       "      <td>2025-10-01 12:01:15+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-10-01 12:01:22.025362+00:00</td>\n",
       "      <td>2025-10-01 12:01:22.025362+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    sensor_id                        ts  value_mm  qc_flags  \\\n",
       "0  636194     pluvio_1 2025-10-01 12:01:15+00:00       0.0         0   \n",
       "1  636195    pluvio_10 2025-10-01 12:01:15+00:00       0.0         2   \n",
       "2  636196  pluvio_1019 2025-10-01 12:01:15+00:00       0.0         0   \n",
       "3  636197   pluvio_105 2025-10-01 12:01:15+00:00       0.0         0   \n",
       "4  636198    pluvio_11 2025-10-01 12:01:15+00:00       0.0         0   \n",
       "\n",
       "  imputation_method  version                       created_at  \\\n",
       "0              None        1 2025-10-01 12:01:22.025362+00:00   \n",
       "1     global_median        1 2025-10-01 12:01:22.025362+00:00   \n",
       "2              None        1 2025-10-01 12:01:22.025362+00:00   \n",
       "3              None        1 2025-10-01 12:01:22.025362+00:00   \n",
       "4              None        1 2025-10-01 12:01:22.025362+00:00   \n",
       "\n",
       "                        updated_at  \n",
       "0 2025-10-01 12:01:22.025362+00:00  \n",
       "1 2025-10-01 12:01:22.025362+00:00  \n",
       "2 2025-10-01 12:01:22.025362+00:00  \n",
       "3 2025-10-01 12:01:22.025362+00:00  \n",
       "4 2025-10-01 12:01:22.025362+00:00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch clean measurements from last 30 days\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    sensor_id,\n",
    "    ts,\n",
    "    value_mm,\n",
    "    qc_flags,\n",
    "    imputation_method,\n",
    "    version,\n",
    "    created_at,\n",
    "    updated_at\n",
    "FROM clean_measurements\n",
    "WHERE ts >= NOW() - INTERVAL '30 days'\n",
    "ORDER BY ts DESC, sensor_id;\n",
    "\"\"\"\n",
    "\n",
    "clean_measurements_df = pd.read_sql(query, engine)\n",
    "\n",
    "print(f\"✓ Fetched {len(clean_measurements_df):,} clean measurements\")\n",
    "if len(clean_measurements_df) > 0:\n",
    "    print(f\"  Date range: {clean_measurements_df['ts'].min()} to {clean_measurements_df['ts'].max()}\")\n",
    "    print(f\"  Unique sensors: {clean_measurements_df['sensor_id'].nunique()}\")\n",
    "    print(f\"  Total measurements per sensor (avg): {len(clean_measurements_df) / clean_measurements_df['sensor_id'].nunique():.1f}\")\n",
    "\n",
    "clean_measurements_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93aba532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved clean measurements to: data_backup/backup_20251001_121447/clean_measurements.json\n",
      "  File size: 21530.34 KB\n"
     ]
    }
   ],
   "source": [
    "# Save clean measurements to JSON (chunked if large)\n",
    "clean_file = BACKUP_SUBDIR / \"clean_measurements.json\"\n",
    "\n",
    "# Convert timestamps to ISO format\n",
    "clean_export = clean_measurements_df.copy()\n",
    "clean_export['ts'] = clean_export['ts'].astype(str)\n",
    "clean_export['created_at'] = clean_export['created_at'].astype(str)\n",
    "clean_export['updated_at'] = clean_export['updated_at'].astype(str)\n",
    "\n",
    "# Convert to dict and save\n",
    "clean_data = clean_export.to_dict(orient='records')\n",
    "\n",
    "# If file is too large (>50MB), split into chunks\n",
    "import sys\n",
    "data_size = sys.getsizeof(json.dumps(clean_data, default=str))\n",
    "\n",
    "if data_size > 50 * 1024 * 1024:  # 50 MB\n",
    "    print(f\"  Data size: {data_size / (1024*1024):.2f} MB - splitting into chunks\")\n",
    "    chunk_size = 10000\n",
    "    for i in range(0, len(clean_data), chunk_size):\n",
    "        chunk = clean_data[i:i+chunk_size]\n",
    "        chunk_file = BACKUP_SUBDIR / f\"clean_measurements_chunk_{i//chunk_size + 1}.json\"\n",
    "        with open(chunk_file, 'w') as f:\n",
    "            json.dump(chunk, f, indent=2, default=str)\n",
    "        print(f\"  ✓ Saved chunk {i//chunk_size + 1} ({len(chunk)} records)\")\n",
    "else:\n",
    "    with open(clean_file, 'w') as f:\n",
    "        json.dump(clean_data, f, indent=2, default=str)\n",
    "    print(f\"✓ Saved clean measurements to: {clean_file}\")\n",
    "    print(f\"  File size: {clean_file.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13e785f",
   "metadata": {},
   "source": [
    "## 4. Fetch Grid Runs Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55bb6a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fetched 277 grid runs\n",
      "  Date range: 2025-09-29 00:00:00+00:00 to 2025-10-01 11:00:00+00:00\n",
      "  Status breakdown:\n",
      "status\n",
      "done      273\n",
      "failed      4\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ts",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "res_m",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "bbox",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "crs",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "blob_url_json",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "blob_url_npz",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "blob_url_contours",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "message",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "created_at",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "updated_at",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        }
       ],
       "ref": "6d5d7011-056d-4701-949b-f21d35a11dc5",
       "rows": [
        [
         "0",
         "318",
         "2025-10-01 11:00:00+00:00",
         "500",
         "[-8533035.968636995, 604561.383004428, -8307053.104129183, 973544.8517950282]",
         "EPSG:3857",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T110000Z/grid.json.gz",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T110000Z/grid.npz",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T110000Z/contours.geojson",
         "done",
         null,
         "2025-10-01 12:00:59.192186+00:00",
         "2025-10-01 12:01:01.936731+00:00"
        ],
        [
         "1",
         "317",
         "2025-10-01 10:00:00+00:00",
         "500",
         "[-8533035.968636995, 604561.383004428, -8307053.104129183, 973544.8517950282]",
         "EPSG:3857",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T100000Z/grid.json.gz",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T100000Z/grid.npz",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T100000Z/contours.geojson",
         "done",
         null,
         "2025-10-01 11:00:41.891752+00:00",
         "2025-10-01 11:00:44.845568+00:00"
        ],
        [
         "2",
         "316",
         "2025-10-01 09:00:00+00:00",
         "500",
         "[-8533035.968636995, 604561.383004428, -8307053.104129183, 973544.8517950282]",
         "EPSG:3857",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T090000Z/grid.json.gz",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T090000Z/grid.npz",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T090000Z/contours.geojson",
         "done",
         null,
         "2025-10-01 10:00:44.118530+00:00",
         "2025-10-01 10:00:46.387564+00:00"
        ],
        [
         "3",
         "315",
         "2025-10-01 08:00:00+00:00",
         "500",
         "[-8533035.968636995, 604561.383004428, -8307053.104129183, 973544.8517950282]",
         "EPSG:3857",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T080000Z/grid.json.gz",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T080000Z/grid.npz",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T080000Z/contours.geojson",
         "done",
         null,
         "2025-10-01 09:00:36.753405+00:00",
         "2025-10-01 09:00:39.334860+00:00"
        ],
        [
         "4",
         "314",
         "2025-10-01 07:00:00+00:00",
         "500",
         "[-8533035.968636995, 604561.383004428, -8307053.104129183, 973544.8517950282]",
         "EPSG:3857",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T070000Z/grid.json.gz",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T070000Z/grid.npz",
         "https://nt9pzjxsvf6ahuq3.public.blob.vercel-storage.com/grids/20251001T070000Z/contours.geojson",
         "done",
         null,
         "2025-10-01 08:00:39.877302+00:00",
         "2025-10-01 08:00:42.088216+00:00"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ts</th>\n",
       "      <th>res_m</th>\n",
       "      <th>bbox</th>\n",
       "      <th>crs</th>\n",
       "      <th>blob_url_json</th>\n",
       "      <th>blob_url_npz</th>\n",
       "      <th>blob_url_contours</th>\n",
       "      <th>status</th>\n",
       "      <th>message</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318</td>\n",
       "      <td>2025-10-01 11:00:00+00:00</td>\n",
       "      <td>500</td>\n",
       "      <td>[-8533035.968636995, 604561.383004428, -830705...</td>\n",
       "      <td>EPSG:3857</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>done</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-10-01 12:00:59.192186+00:00</td>\n",
       "      <td>2025-10-01 12:01:01.936731+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317</td>\n",
       "      <td>2025-10-01 10:00:00+00:00</td>\n",
       "      <td>500</td>\n",
       "      <td>[-8533035.968636995, 604561.383004428, -830705...</td>\n",
       "      <td>EPSG:3857</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>done</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-10-01 11:00:41.891752+00:00</td>\n",
       "      <td>2025-10-01 11:00:44.845568+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>2025-10-01 09:00:00+00:00</td>\n",
       "      <td>500</td>\n",
       "      <td>[-8533035.968636995, 604561.383004428, -830705...</td>\n",
       "      <td>EPSG:3857</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>done</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-10-01 10:00:44.118530+00:00</td>\n",
       "      <td>2025-10-01 10:00:46.387564+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2025-10-01 08:00:00+00:00</td>\n",
       "      <td>500</td>\n",
       "      <td>[-8533035.968636995, 604561.383004428, -830705...</td>\n",
       "      <td>EPSG:3857</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>done</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-10-01 09:00:36.753405+00:00</td>\n",
       "      <td>2025-10-01 09:00:39.334860+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>2025-10-01 07:00:00+00:00</td>\n",
       "      <td>500</td>\n",
       "      <td>[-8533035.968636995, 604561.383004428, -830705...</td>\n",
       "      <td>EPSG:3857</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...</td>\n",
       "      <td>done</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-10-01 08:00:39.877302+00:00</td>\n",
       "      <td>2025-10-01 08:00:42.088216+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                        ts  res_m  \\\n",
       "0  318 2025-10-01 11:00:00+00:00    500   \n",
       "1  317 2025-10-01 10:00:00+00:00    500   \n",
       "2  316 2025-10-01 09:00:00+00:00    500   \n",
       "3  315 2025-10-01 08:00:00+00:00    500   \n",
       "4  314 2025-10-01 07:00:00+00:00    500   \n",
       "\n",
       "                                                bbox        crs  \\\n",
       "0  [-8533035.968636995, 604561.383004428, -830705...  EPSG:3857   \n",
       "1  [-8533035.968636995, 604561.383004428, -830705...  EPSG:3857   \n",
       "2  [-8533035.968636995, 604561.383004428, -830705...  EPSG:3857   \n",
       "3  [-8533035.968636995, 604561.383004428, -830705...  EPSG:3857   \n",
       "4  [-8533035.968636995, 604561.383004428, -830705...  EPSG:3857   \n",
       "\n",
       "                                       blob_url_json  \\\n",
       "0  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   \n",
       "1  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   \n",
       "2  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   \n",
       "3  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   \n",
       "4  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   \n",
       "\n",
       "                                        blob_url_npz  \\\n",
       "0  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   \n",
       "1  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   \n",
       "2  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   \n",
       "3  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   \n",
       "4  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   \n",
       "\n",
       "                                   blob_url_contours status message  \\\n",
       "0  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   done    None   \n",
       "1  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   done    None   \n",
       "2  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   done    None   \n",
       "3  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   done    None   \n",
       "4  https://nt9pzjxsvf6ahuq3.public.blob.vercel-st...   done    None   \n",
       "\n",
       "                        created_at                       updated_at  \n",
       "0 2025-10-01 12:00:59.192186+00:00 2025-10-01 12:01:01.936731+00:00  \n",
       "1 2025-10-01 11:00:41.891752+00:00 2025-10-01 11:00:44.845568+00:00  \n",
       "2 2025-10-01 10:00:44.118530+00:00 2025-10-01 10:00:46.387564+00:00  \n",
       "3 2025-10-01 09:00:36.753405+00:00 2025-10-01 09:00:39.334860+00:00  \n",
       "4 2025-10-01 08:00:39.877302+00:00 2025-10-01 08:00:42.088216+00:00  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch grid runs from last 30 days\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    ts,\n",
    "    res_m,\n",
    "    bbox,\n",
    "    crs,\n",
    "    blob_url_json,\n",
    "    blob_url_npz,\n",
    "    blob_url_contours,\n",
    "    status,\n",
    "    message,\n",
    "    created_at,\n",
    "    updated_at\n",
    "FROM grid_runs\n",
    "WHERE ts >= NOW() - INTERVAL '30 days'\n",
    "ORDER BY ts DESC;\n",
    "\"\"\"\n",
    "\n",
    "grid_runs_df = pd.read_sql(query, engine)\n",
    "\n",
    "print(f\"✓ Fetched {len(grid_runs_df)} grid runs\")\n",
    "if len(grid_runs_df) > 0:\n",
    "    print(f\"  Date range: {grid_runs_df['ts'].min()} to {grid_runs_df['ts'].max()}\")\n",
    "    print(f\"  Status breakdown:\")\n",
    "    print(grid_runs_df['status'].value_counts().to_string())\n",
    "\n",
    "grid_runs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7510459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved grid runs to: data_backup/backup_20251001_121447/grid_runs.json\n",
      "  File size: 188.90 KB\n"
     ]
    }
   ],
   "source": [
    "# Save grid runs to JSON\n",
    "grid_file = BACKUP_SUBDIR / \"grid_runs.json\"\n",
    "\n",
    "# Convert timestamps to ISO format\n",
    "grid_export = grid_runs_df.copy()\n",
    "grid_export['ts'] = grid_export['ts'].astype(str)\n",
    "grid_export['created_at'] = grid_export['created_at'].astype(str)\n",
    "grid_export['updated_at'] = grid_export['updated_at'].astype(str)\n",
    "# Convert bbox JSONB to string\n",
    "grid_export['bbox'] = grid_export['bbox'].astype(str)\n",
    "\n",
    "# Convert to dict and save\n",
    "grid_data = grid_export.to_dict(orient='records')\n",
    "with open(grid_file, 'w') as f:\n",
    "    json.dump(grid_data, f, indent=2, default=str)\n",
    "\n",
    "print(f\"✓ Saved grid runs to: {grid_file}\")\n",
    "print(f\"  File size: {grid_file.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61fb5e7",
   "metadata": {},
   "source": [
    "## 5. Fetch Raw Measurements (Last 7 days only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5a13a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fetched 75,032 raw measurements (current, last 7 days)\n",
      "  Date range: 2025-09-29 00:50:51+00:00 to 2025-10-01 12:10:49+00:00\n",
      "  Unique sensors: 226\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sensor_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ts",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "value_mm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "variable",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ingested_at",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "created_at",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "updated_at",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        }
       ],
       "ref": "5a17ef6c-16d8-481d-95f6-bc7419a706be",
       "rows": [
        [
         "0",
         "636434",
         "pluvio_1",
         "2025-10-01 12:10:49+00:00",
         "0.0",
         null,
         "precipitacion",
         "current",
         "2025-10-01 12:10:50.592896+00:00",
         "2025-10-01 12:10:50.592896+00:00",
         "2025-10-01 12:10:50.592896+00:00"
        ],
        [
         "1",
         "636422",
         "pluvio_10",
         "2025-10-01 12:10:49+00:00",
         null,
         null,
         "precipitacion",
         "current",
         "2025-10-01 12:10:50.592896+00:00",
         "2025-10-01 12:10:50.592896+00:00",
         "2025-10-01 12:10:50.592896+00:00"
        ],
        [
         "2",
         "636629",
         "pluvio_1019",
         "2025-10-01 12:10:49+00:00",
         "0.0",
         null,
         "precipitacion",
         "current",
         "2025-10-01 12:10:50.592896+00:00",
         "2025-10-01 12:10:50.592896+00:00",
         "2025-10-01 12:10:50.592896+00:00"
        ],
        [
         "3",
         "636500",
         "pluvio_105",
         "2025-10-01 12:10:49+00:00",
         "0.0",
         null,
         "precipitacion",
         "current",
         "2025-10-01 12:10:50.592896+00:00",
         "2025-10-01 12:10:50.592896+00:00",
         "2025-10-01 12:10:50.592896+00:00"
        ],
        [
         "4",
         "636425",
         "pluvio_11",
         "2025-10-01 12:10:49+00:00",
         "0.0",
         null,
         "precipitacion",
         "current",
         "2025-10-01 12:10:50.592896+00:00",
         "2025-10-01 12:10:50.592896+00:00",
         "2025-10-01 12:10:50.592896+00:00"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>value_mm</th>\n",
       "      <th>quality</th>\n",
       "      <th>variable</th>\n",
       "      <th>source</th>\n",
       "      <th>ingested_at</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>636434</td>\n",
       "      <td>pluvio_1</td>\n",
       "      <td>2025-10-01 12:10:49+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>precipitacion</td>\n",
       "      <td>current</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>636422</td>\n",
       "      <td>pluvio_10</td>\n",
       "      <td>2025-10-01 12:10:49+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>precipitacion</td>\n",
       "      <td>current</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>636629</td>\n",
       "      <td>pluvio_1019</td>\n",
       "      <td>2025-10-01 12:10:49+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>precipitacion</td>\n",
       "      <td>current</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>636500</td>\n",
       "      <td>pluvio_105</td>\n",
       "      <td>2025-10-01 12:10:49+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>precipitacion</td>\n",
       "      <td>current</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636425</td>\n",
       "      <td>pluvio_11</td>\n",
       "      <td>2025-10-01 12:10:49+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>precipitacion</td>\n",
       "      <td>current</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "      <td>2025-10-01 12:10:50.592896+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    sensor_id                        ts  value_mm  quality  \\\n",
       "0  636434     pluvio_1 2025-10-01 12:10:49+00:00       0.0      NaN   \n",
       "1  636422    pluvio_10 2025-10-01 12:10:49+00:00       NaN      NaN   \n",
       "2  636629  pluvio_1019 2025-10-01 12:10:49+00:00       0.0      NaN   \n",
       "3  636500   pluvio_105 2025-10-01 12:10:49+00:00       0.0      NaN   \n",
       "4  636425    pluvio_11 2025-10-01 12:10:49+00:00       0.0      NaN   \n",
       "\n",
       "        variable   source                      ingested_at  \\\n",
       "0  precipitacion  current 2025-10-01 12:10:50.592896+00:00   \n",
       "1  precipitacion  current 2025-10-01 12:10:50.592896+00:00   \n",
       "2  precipitacion  current 2025-10-01 12:10:50.592896+00:00   \n",
       "3  precipitacion  current 2025-10-01 12:10:50.592896+00:00   \n",
       "4  precipitacion  current 2025-10-01 12:10:50.592896+00:00   \n",
       "\n",
       "                        created_at                       updated_at  \n",
       "0 2025-10-01 12:10:50.592896+00:00 2025-10-01 12:10:50.592896+00:00  \n",
       "1 2025-10-01 12:10:50.592896+00:00 2025-10-01 12:10:50.592896+00:00  \n",
       "2 2025-10-01 12:10:50.592896+00:00 2025-10-01 12:10:50.592896+00:00  \n",
       "3 2025-10-01 12:10:50.592896+00:00 2025-10-01 12:10:50.592896+00:00  \n",
       "4 2025-10-01 12:10:50.592896+00:00 2025-10-01 12:10:50.592896+00:00  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch raw measurements from last 7 days (non-historic)\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    sensor_id,\n",
    "    ts,\n",
    "    value_mm,\n",
    "    quality,\n",
    "    variable,\n",
    "    source,\n",
    "    ingested_at,\n",
    "    created_at,\n",
    "    updated_at\n",
    "FROM raw_measurements\n",
    "WHERE ts >= NOW() - INTERVAL '7 days'\n",
    "  AND source = 'current'\n",
    "ORDER BY ts DESC, sensor_id;\n",
    "\"\"\"\n",
    "\n",
    "raw_measurements_df = pd.read_sql(query, engine)\n",
    "\n",
    "print(f\"✓ Fetched {len(raw_measurements_df):,} raw measurements (current, last 7 days)\")\n",
    "if len(raw_measurements_df) > 0:\n",
    "    print(f\"  Date range: {raw_measurements_df['ts'].min()} to {raw_measurements_df['ts'].max()}\")\n",
    "    print(f\"  Unique sensors: {raw_measurements_df['sensor_id'].nunique()}\")\n",
    "\n",
    "raw_measurements_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13efc23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved raw measurements to: data_backup/backup_20251001_121447/raw_measurements_current.json\n",
      "  File size: 26200.34 KB\n"
     ]
    }
   ],
   "source": [
    "# Save raw measurements to JSON\n",
    "raw_file = BACKUP_SUBDIR / \"raw_measurements_current.json\"\n",
    "\n",
    "# Convert timestamps to ISO format\n",
    "raw_export = raw_measurements_df.copy()\n",
    "raw_export['ts'] = raw_export['ts'].astype(str)\n",
    "raw_export['ingested_at'] = raw_export['ingested_at'].astype(str)\n",
    "raw_export['created_at'] = raw_export['created_at'].astype(str)\n",
    "raw_export['updated_at'] = raw_export['updated_at'].astype(str)\n",
    "\n",
    "# Convert to dict and save\n",
    "raw_data = raw_export.to_dict(orient='records')\n",
    "\n",
    "# Check size and split if needed\n",
    "data_size = sys.getsizeof(json.dumps(raw_data, default=str))\n",
    "\n",
    "if data_size > 50 * 1024 * 1024:  # 50 MB\n",
    "    print(f\"  Data size: {data_size / (1024*1024):.2f} MB - splitting into chunks\")\n",
    "    chunk_size = 10000\n",
    "    for i in range(0, len(raw_data), chunk_size):\n",
    "        chunk = raw_data[i:i+chunk_size]\n",
    "        chunk_file = BACKUP_SUBDIR / f\"raw_measurements_current_chunk_{i//chunk_size + 1}.json\"\n",
    "        with open(chunk_file, 'w') as f:\n",
    "            json.dump(chunk, f, indent=2, default=str)\n",
    "        print(f\"  ✓ Saved chunk {i//chunk_size + 1} ({len(chunk)} records)\")\n",
    "else:\n",
    "    with open(raw_file, 'w') as f:\n",
    "        json.dump(raw_data, f, indent=2, default=str)\n",
    "    print(f\"✓ Saved raw measurements to: {raw_file}\")\n",
    "    print(f\"  File size: {raw_file.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5661d4",
   "metadata": {},
   "source": [
    "## 6. Create Backup Manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5a30d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Backup manifest created\n",
      "\n",
      "Backup Summary:\n",
      "  Sensors: 239\n",
      "  Clean Measurements: 74,806\n",
      "  Raw Measurements: 75,032\n",
      "  Grid Runs: 277\n",
      "\n",
      "  Imputation: ARIMA (fallback: 0 (zero))\n",
      "\n",
      "  Files created: 4\n",
      "  Location: data_backup/backup_20251001_121447\n"
     ]
    }
   ],
   "source": [
    "# Create manifest with backup metadata\n",
    "manifest = {\n",
    "    \"backup_timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"backup_type\": \"current_non_historic_data\",\n",
    "    \"description\": \"Backup of current operational data before refactoring\",\n",
    "    \"data_range\": {\n",
    "        \"clean_measurements\": \"Last 30 days\",\n",
    "        \"raw_measurements\": \"Last 7 days (current source only)\",\n",
    "        \"grid_runs\": \"Last 30 days\"\n",
    "    },\n",
    "    \"counts\": {\n",
    "        \"sensors\": len(sensors_df),\n",
    "        \"clean_measurements\": len(clean_measurements_df),\n",
    "        \"raw_measurements\": len(raw_measurements_df),\n",
    "        \"grid_runs\": len(grid_runs_df)\n",
    "    },\n",
    "    \"imputation_strategy\": {\n",
    "        \"primary_method\": \"ARIMA\",\n",
    "        \"fallback_method\": \"0 (zero)\",\n",
    "        \"notes\": \"Clean measurements may contain imputed values using ARIMA or 0 as fallback\"\n",
    "    },\n",
    "    \"files\": [\n",
    "        str(f.name) for f in BACKUP_SUBDIR.glob(\"*.json\")\n",
    "    ],\n",
    "    \"database_info\": {\n",
    "        \"url_host\": DATABASE_URL.split('@')[1].split('/')[0] if '@' in DATABASE_URL else 'configured',\n",
    "        \"backup_date\": datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
    "    },\n",
    "    \"recovery_notes\": [\n",
    "        \"This backup contains current operational data only (non-historic).\",\n",
    "        \"To restore: use the recovery notebook or import JSON files manually.\",\n",
    "        \"Files are in JSON format for easy inspection and recovery.\",\n",
    "        \"Large files may be split into chunks.\",\n",
    "        \"Clean measurements may include ARIMA-imputed values (with 0 as fallback).\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "manifest_file = BACKUP_SUBDIR / \"MANIFEST.json\"\n",
    "with open(manifest_file, 'w') as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "print(\"✓ Backup manifest created\")\n",
    "print(\"\\nBackup Summary:\")\n",
    "print(f\"  Sensors: {manifest['counts']['sensors']:,}\")\n",
    "print(f\"  Clean Measurements: {manifest['counts']['clean_measurements']:,}\")\n",
    "print(f\"  Raw Measurements: {manifest['counts']['raw_measurements']:,}\")\n",
    "print(f\"  Grid Runs: {manifest['counts']['grid_runs']:,}\")\n",
    "print(f\"\\n  Imputation: {manifest['imputation_strategy']['primary_method']} (fallback: {manifest['imputation_strategy']['fallback_method']})\")\n",
    "print(f\"\\n  Files created: {len(manifest['files'])}\")\n",
    "print(f\"  Location: {BACKUP_SUBDIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0813621",
   "metadata": {},
   "source": [
    "## 7. Create README for Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "730874f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ README created: data_backup/backup_20251001_121447/README.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:141: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:141: SyntaxWarning: invalid escape sequence '\\*'\n",
      "/tmp/ipykernel_25504/1639873933.py:141: SyntaxWarning: invalid escape sequence '\\*'\n"
     ]
    }
   ],
   "source": [
    "# Create README with recovery instructions\n",
    "readme_content = f\"\"\"# Data Backup - {timestamp}\n",
    "\n",
    "## Backup Information\n",
    "\n",
    "**Date:** {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}\n",
    "**Type:** Current Non-Historic Data\n",
    "**Purpose:** Pre-refactoring backup\n",
    "\n",
    "## Contents\n",
    "\n",
    "- `sensors.json` - All sensor metadata ({manifest['counts']['sensors']} sensors)\n",
    "- `clean_measurements*.json` - Clean measurements from last 30 days ({manifest['counts']['clean_measurements']:,} records)\n",
    "- `raw_measurements_current*.json` - Raw measurements from last 7 days ({manifest['counts']['raw_measurements']:,} records)\n",
    "- `grid_runs.json` - Grid runs from last 30 days ({manifest['counts']['grid_runs']} runs)\n",
    "- `MANIFEST.json` - Backup metadata and file list\n",
    "\n",
    "## Data Ranges\n",
    "\n",
    "- **Clean Measurements:** Last 30 days\n",
    "- **Raw Measurements:** Last 7 days (current source only, non-historic)\n",
    "- **Grid Runs:** Last 30 days\n",
    "- **Sensors:** All sensors\n",
    "\n",
    "## Data Quality & Imputation\n",
    "\n",
    "Clean measurements may include imputed values:\n",
    "- **Primary Method:** ARIMA (AutoRegressive Integrated Moving Average)\n",
    "- **Fallback Method:** 0 (zero) when ARIMA cannot be applied\n",
    "- Check the `imputation_method` field in clean_measurements to identify imputed values\n",
    "\n",
    "## Recovery Instructions\n",
    "\n",
    "### Option 1: Using Recovery Notebook\n",
    "\n",
    "1. Open `notebooks/00_restore_backup.ipynb`\n",
    "2. Update the backup path to point to this directory\n",
    "3. Run all cells\n",
    "\n",
    "### Option 2: Manual Recovery (Python)\n",
    "\n",
    "```python\n",
    "import json\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "\n",
    "# Load data\n",
    "with open('sensors.json') as f:\n",
    "    sensors = json.load(f)\n",
    "\n",
    "# Create DataFrame\n",
    "sensors_df = pd.DataFrame(sensors)\n",
    "\n",
    "# Insert into database\n",
    "engine = sa.create_engine(DATABASE_URL)\n",
    "sensors_df.to_sql('sensors', engine, if_exists='append', index=False)\n",
    "```\n",
    "\n",
    "### Option 3: Direct SQL Import\n",
    "\n",
    "Use the `00_restore_backup.ipynb` notebook for automated restoration.\n",
    "\n",
    "## Notes\n",
    "\n",
    "- All timestamps are in UTC\n",
    "- Large files are split into chunks (\\*_chunk_\\*.json)\n",
    "- JSON files use standard formatting for easy inspection\n",
    "- This backup contains operational data only (excludes historic data)\n",
    "- Clean measurements may contain ARIMA-imputed values (check `imputation_method` field)\n",
    "\n",
    "## Verification\n",
    "\n",
    "After recovery, verify counts match:\n",
    "- Sensors: {manifest['counts']['sensors']:,}\n",
    "- Clean Measurements: {manifest['counts']['clean_measurements']:,}\n",
    "- Raw Measurements: {manifest['counts']['raw_measurements']:,}\n",
    "- Grid Runs: {manifest['counts']['grid_runs']:,}\n",
    "\n",
    "## Support\n",
    "\n",
    "If you encounter issues during recovery, check:\n",
    "1. Database connection is working\n",
    "2. Required tables exist\n",
    "3. No data conflicts (duplicate IDs)\n",
    "4. Sufficient disk space\n",
    "\n",
    "---\n",
    "\n",
    "**Generated by:** 00_backup_current_data.ipynb\n",
    "\"\"\"\n",
    "\n",
    "readme_file = BACKUP_SUBDIR / \"README.md\"\n",
    "with open(readme_file, 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(f\"✓ README created: {readme_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0f89c",
   "metadata": {},
   "source": [
    "## 8. Verify Backup Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "614da6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying backup integrity...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         file      size_kb        records  status\n",
      "raw_measurements_current.json 26200.342773          75032 ✓ Valid\n",
      "               grid_runs.json   188.895508            277 ✓ Valid\n",
      "                 sensors.json   122.762695            239 ✓ Valid\n",
      "      clean_measurements.json 21530.336914          74806 ✓ Valid\n",
      "                MANIFEST.json     1.226562 N/A (manifest) ✓ Valid\n",
      "\n",
      "Total backup size: 46.92 MB\n",
      "\n",
      "✅ All files verified successfully!\n"
     ]
    }
   ],
   "source": [
    "# Verify all files exist and can be read\n",
    "print(\"Verifying backup integrity...\\n\")\n",
    "\n",
    "verification_results = []\n",
    "\n",
    "for json_file in BACKUP_SUBDIR.glob(\"*.json\"):\n",
    "    try:\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if json_file.name == \"MANIFEST.json\":\n",
    "            status = \"✓ Valid\"\n",
    "            record_count = \"N/A (manifest)\"\n",
    "        else:\n",
    "            record_count = len(data)\n",
    "            status = \"✓ Valid\" if record_count > 0 else \"⚠ Empty\"\n",
    "        \n",
    "        verification_results.append({\n",
    "            'file': json_file.name,\n",
    "            'size_kb': json_file.stat().st_size / 1024,\n",
    "            'records': record_count,\n",
    "            'status': status\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        verification_results.append({\n",
    "            'file': json_file.name,\n",
    "            'size_kb': json_file.stat().st_size / 1024,\n",
    "            'records': 'Error',\n",
    "            'status': f\"✗ Failed: {str(e)}\"\n",
    "        })\n",
    "\n",
    "verification_df = pd.DataFrame(verification_results)\n",
    "print(verification_df.to_string(index=False))\n",
    "\n",
    "# Calculate total size\n",
    "total_size = sum(f.stat().st_size for f in BACKUP_SUBDIR.glob(\"*.json\"))\n",
    "print(f\"\\nTotal backup size: {total_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Check if all verifications passed\n",
    "all_valid = all('✓' in result['status'] for result in verification_results)\n",
    "if all_valid:\n",
    "    print(\"\\n✅ All files verified successfully!\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Some files failed verification - please check the results above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c7d275",
   "metadata": {},
   "source": [
    "## 9. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "156b59fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BACKUP COMPLETED SUCCESSFULLY\n",
      "======================================================================\n",
      "\n",
      "Backup Location: /workspaces/Siata-Contamination-Viewer/notebooks/data_backup/backup_20251001_121447\n",
      "\n",
      "Data Summary:\n",
      "  • Sensors: 239\n",
      "  • Clean Measurements: 74,806 (last 30 days)\n",
      "  • Raw Measurements: 75,032 (last 7 days, non-historic)\n",
      "  • Grid Runs: 277 (last 30 days)\n",
      "\n",
      "Total Files: 6\n",
      "Total Size: 46.92 MB\n",
      "\n",
      "======================================================================\n",
      "NEXT STEPS\n",
      "======================================================================\n",
      "\n",
      "1. Verify backup files are accessible\n",
      "2. Review the refactoring plan in docs/REFACTORING_PLAN.md\n",
      "3. Proceed with database schema changes (Phase 1)\n",
      "4. Keep this backup until refactoring is complete and verified\n",
      "\n",
      "📝 Note: This backup contains ONLY current operational data (non-historic)\n",
      "   Historic data remains in the database and is not affected by the refactoring.\n",
      "\n",
      "✅ You can now safely proceed with the refactoring!\n"
     ]
    }
   ],
   "source": [
    "# Display summary\n",
    "print(\"=\" * 70)\n",
    "print(\"BACKUP COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nBackup Location: {BACKUP_SUBDIR.absolute()}\")\n",
    "print(f\"\\nData Summary:\")\n",
    "print(f\"  • Sensors: {manifest['counts']['sensors']:,}\")\n",
    "print(f\"  • Clean Measurements: {manifest['counts']['clean_measurements']:,} (last 30 days)\")\n",
    "print(f\"  • Raw Measurements: {manifest['counts']['raw_measurements']:,} (last 7 days, non-historic)\")\n",
    "print(f\"  • Grid Runs: {manifest['counts']['grid_runs']:,} (last 30 days)\")\n",
    "print(f\"\\nTotal Files: {len(list(BACKUP_SUBDIR.glob('*')))}\")\n",
    "print(f\"Total Size: {total_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n1. Verify backup files are accessible\")\n",
    "print(\"2. Review the refactoring plan in docs/REFACTORING_PLAN.md\")\n",
    "print(\"3. Proceed with database schema changes (Phase 1)\")\n",
    "print(\"4. Keep this backup until refactoring is complete and verified\")\n",
    "print(\"\\n📝 Note: This backup contains ONLY current operational data (non-historic)\")\n",
    "print(\"   Historic data remains in the database and is not affected by the refactoring.\")\n",
    "print(\"\\n✅ You can now safely proceed with the refactoring!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c731089c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Backup Complete!\n",
    "\n",
    "The backup has been created successfully. All current non-historic data has been exported to JSON format and is ready for recovery if needed.\n",
    "\n",
    "**Important Notes:**\n",
    "- This backup contains only recent operational data (last 30 days for clean data, 7 days for raw data)\n",
    "- Historic data remains untouched in the database\n",
    "- The backup is stored in: `data_backup/backup_TIMESTAMP/`\n",
    "- Use the recovery notebook if you need to restore this data\n",
    "\n",
    "**Before proceeding with refactoring:**\n",
    "1. ✅ Backup complete\n",
    "2. ⏳ Review refactoring plan\n",
    "3. ⏳ Create database schema changes\n",
    "4. ⏳ Update ETL service\n",
    "5. ⏳ Update API service\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fb0e8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Backup folder zipped: data_backup/backup_20251001_121447.zip (1.07 MB)\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path = BACKUP_DIR / f\"{BACKUP_SUBDIR.name}.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for file in BACKUP_SUBDIR.iterdir():\n",
    "        zipf.write(file, arcname=file.name)\n",
    "\n",
    "print(f\"✓ Backup folder zipped: {zip_path} ({zip_path.stat().st_size / (1024*1024):.2f} MB)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shizuku",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
