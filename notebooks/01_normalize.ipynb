{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550305b0",
   "metadata": {},
   "source": [
    "# Step 2 Â· Normalize SIATA feeds\n",
    "\n",
    "This notebook flattens the historic and current precipitation JSON feeds into a common schema ready for loading into PostgreSQL (NeonDB). It also persists intermediate artifacts for inspection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9febe36",
   "metadata": {},
   "source": [
    "## 1. Setup & paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa37000",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=Path('..') / '.env', override=True)\n",
    "\n",
    "BASE_DIR = Path('..').resolve()\n",
    "RAW_DIR = BASE_DIR / 'data' / 'raw'\n",
    "PROCESSED_DIR = BASE_DIR / 'data' / 'processed'\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "HISTORIC_PATH = RAW_DIR / 'historic_precipitation.json'\n",
    "CURRENT_PATH = RAW_DIR / 'current_precipitation.json'\n",
    "\n",
    "HISTORIC_PATH, CURRENT_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c2a90d",
   "metadata": {},
   "source": [
    "## 2. Load raw feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9058059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with HISTORIC_PATH.open() as f:\n",
    "    historic_raw = json.load(f)\n",
    "\n",
    "with CURRENT_PATH.open() as f:\n",
    "    current_raw = json.load(f)\n",
    "\n",
    "len(historic_raw), len(current_raw['estaciones'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4ec4aa",
   "metadata": {},
   "source": [
    "## 3. Normalize sensor metadata\n",
    "\n",
    "We create a unified `sensors` table with deterministic IDs. Historic Vaisala stations are prefixed with `vaisala_`, current pluvio stations with `pluvio_`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2539e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_float(value: Any) -> float | None:\n",
    "    try:\n",
    "        if value is None:\n",
    "            return None\n",
    "        if isinstance(value, str) and not value.strip():\n",
    "            return None\n",
    "        return float(value)\n",
    "    except (TypeError, ValueError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def normalize_historic_sensors(raw: Iterable[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    records: List[Dict[str, Any]] = []\n",
    "    for item in raw:\n",
    "        codigo = str(item.get('codigo'))\n",
    "        sensor_id = f\"vaisala_{codigo}\"\n",
    "        records.append({\n",
    "            'id': sensor_id,\n",
    "            'provider_id': codigo,\n",
    "            'name': item.get('nombre'),\n",
    "            'lat': to_float(item.get('latitud')),\n",
    "            'lon': to_float(item.get('longitud')),\n",
    "            'elevation_m': None,\n",
    "            'city': item.get('ciudad'),\n",
    "            'subbasin': item.get('subcuenca'),\n",
    "            'barrio': None,\n",
    "            'metadata': {\n",
    "                'source': 'historic',\n",
    "                'raw': {\n",
    "                    'latitud': item.get('latitud'),\n",
    "                    'longitud': item.get('longitud'),\n",
    "                    'subcuenca': item.get('subcuenca'),\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "def normalize_current_sensors(raw: Iterable[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    records: List[Dict[str, Any]] = []\n",
    "    for item in raw:\n",
    "        codigo = str(item.get('codigo'))\n",
    "        sensor_id = f\"pluvio_{codigo}\"\n",
    "        records.append({\n",
    "            'id': sensor_id,\n",
    "            'provider_id': codigo,\n",
    "            'name': item.get('nombre'),\n",
    "            'lat': to_float(item.get('latitud')),\n",
    "            'lon': to_float(item.get('longitud')),\n",
    "            'elevation_m': None,\n",
    "            'city': item.get('ciudad'),\n",
    "            'subbasin': item.get('subcuenca'),\n",
    "            'barrio': item.get('barrio'),\n",
    "            'metadata': {\n",
    "                'source': 'current',\n",
    "                'comuna': item.get('comuna'),\n",
    "            }\n",
    "        })\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "historic_sensors_df = normalize_historic_sensors(historic_raw)\n",
    "current_sensors_df = normalize_current_sensors(current_raw['estaciones'])\n",
    "\n",
    "sensors_df = (\n",
    "    pd.concat([historic_sensors_df, current_sensors_df], ignore_index=True)\n",
    "    .drop_duplicates(subset=['id'])\n",
    ")\n",
    "\n",
    "print('Historic sensors:', len(historic_sensors_df))\n",
    "print('Current sensors:', len(current_sensors_df))\n",
    "print('Combined sensors:', len(sensors_df))\n",
    "sensors_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c9e7c",
   "metadata": {},
   "source": [
    "## 4. Flatten measurement records\n",
    "\n",
    "Historic feed contains high-frequency minute data per station. The current feed only reports the latest reading per station; we tag those with the retrieval timestamp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e7e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "def normalize_historic_measurements(raw: Iterable[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    records: List[Dict[str, Any]] = []\n",
    "    for item in raw:\n",
    "        sensor_id = f\"vaisala_{item.get('codigo')}\"\n",
    "        for slot in item.get('datos', []):\n",
    "            ts_str = slot.get('fecha')\n",
    "            try:\n",
    "                ts = pd.to_datetime(ts_str, utc=True)\n",
    "            except Exception:\n",
    "                ts = pd.NaT\n",
    "            for var_entry in slot.get('datos', []):\n",
    "                records.append({\n",
    "                    'sensor_id': sensor_id,\n",
    "                    'ts': ts,\n",
    "                    'value_mm': to_float(var_entry.get('valor')),\n",
    "                    'quality': to_float(var_entry.get('calidad')),\n",
    "                    'variable': var_entry.get('variableConsulta'),\n",
    "                    'source': 'historic'\n",
    "                })\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    # Filter to precipitation variable (defensive if other variables appear)\n",
    "    if not df.empty:\n",
    "        df = df[df['variable'] == 'precipitacion']\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_current_measurements(raw: Iterable[Dict[str, Any]], retrieval_ts: datetime) -> pd.DataFrame:\n",
    "    records: List[Dict[str, Any]] = []\n",
    "    for item in raw:\n",
    "        sensor_id = f\"pluvio_{item.get('codigo')}\"\n",
    "        value = to_float(item.get('valor'))\n",
    "        if value is not None and value < 0:\n",
    "            # Current feed uses -999 for missing values\n",
    "            value = None\n",
    "        records.append({\n",
    "            'sensor_id': sensor_id,\n",
    "            'ts': pd.Timestamp(retrieval_ts),\n",
    "            'value_mm': value,\n",
    "            'quality': None,\n",
    "            'variable': 'precipitacion',\n",
    "            'source': 'current'\n",
    "        })\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "historic_measurements_df = normalize_historic_measurements(historic_raw)\n",
    "current_measurements_df = normalize_current_measurements(\n",
    "    current_raw['estaciones'],\n",
    "    retrieval_ts=datetime.now(timezone.utc).replace(microsecond=0)\n",
    ")\n",
    "\n",
    "print('Historic measurements:', len(historic_measurements_df))\n",
    "print('Current measurements:', len(current_measurements_df))\n",
    "\n",
    "combined_measurements_df = pd.concat(\n",
    "    [historic_measurements_df, current_measurements_df],\n",
    "    ignore_index=True\n",
    ")\n",
    "combined_measurements_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0775c4fb",
   "metadata": {},
   "source": [
    "### Quick inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_measurements_df.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded7071b",
   "metadata": {},
   "source": [
    "## 5. Persist normalized artifacts\n",
    "\n",
    "We save the normalized outputs for downstream services and for verifying the transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sensors_output = PROCESSED_DIR / 'sensors_normalized.parquet'\n",
    "measurements_output = PROCESSED_DIR / 'measurements_normalized.parquet'\n",
    "\n",
    "sensors_df.to_parquet(sensors_output, index=False)\n",
    "combined_measurements_df.to_parquet(measurements_output, index=False)\n",
    "\n",
    "sensors_output, measurements_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c923f8e",
   "metadata": {},
   "source": [
    "## 6. Load into PostgreSQL (NeonDB)\n",
    "\n",
    "The following cell performs idempotent upserts into the schema defined in `db/schema.sql`. Configure `DATABASE_URL` in `.env` before running. The helper uses PostgreSQL `ON CONFLICT` to avoid duplicating records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77109e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "\n",
    "\n",
    "DATABASE_URL = os.getenv('DATABASE_URL')\n",
    "if not DATABASE_URL:\n",
    "    raise RuntimeError('DATABASE_URL not set; update .env before loading data.')\n",
    "\n",
    "engine = sa.create_engine(DATABASE_URL, pool_pre_ping=True, future=True)\n",
    "\n",
    "sensors_records = sensors_df.to_dict(orient='records')\n",
    "measurements_records = combined_measurements_df.to_dict(orient='records')\n",
    "\n",
    "metadata = sa.MetaData()\n",
    "sensors_table = sa.Table('sensors', metadata, autoload_with=engine)\n",
    "raw_measurements_table = sa.Table('raw_measurements', metadata, autoload_with=engine)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    if sensors_records:\n",
    "        stmt = insert(sensors_table).values(sensors_records)\n",
    "        update_cols = {col.name: col for col in stmt.excluded if col.name not in ('id',)}\n",
    "        conn.execute(stmt.on_conflict_do_update(index_elements=['id'], set_=update_cols))\n",
    "\n",
    "    if measurements_records:\n",
    "        stmt = insert(raw_measurements_table).values(measurements_records)\n",
    "        conn.execute(\n",
    "            stmt.on_conflict_do_update(\n",
    "                index_elements=['sensor_id', 'ts'],\n",
    "                set_={\n",
    "                    'value_mm': stmt.excluded.value_mm,\n",
    "                    'quality': stmt.excluded.quality,\n",
    "                    'variable': stmt.excluded.variable,\n",
    "                    'source': stmt.excluded.source,\n",
    "                    'updated_at': sa.func.now()\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "print('Load completed')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siata-viewer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
